## 1\. 文档上传与知识库构建 (传统编程实现)

这个阶段将完全通过传统的编程方式来处理，不涉及 CrewAI Agent。

### 1.1 核心流程

1.  **用户上传文件：** 用户通过前端界面或 API 上传 PDF 或 Word 文档。
2.  **文件接收与预处理：**
      * 后端服务（例如，`main.py`中的一个上传接口）接收文件。
      * **文件类型识别：** 判断是 PDF 还是 Word。
      * **图片提取与描述：** 这是关键且复杂的部分。
          * 从 PDF 或 Word 中识别并提取图片。
          * **图片本地存储：** 将提取出的图片保存到指定的本地文件夹（例如 `rag/knowledge/images`）。
          * **多模态 LLM 描述：** 调用 `amazon.titan-embed-image-v1` 或 `claude-3-haiku`（作为工具调用，而非 Agent）来**读取图片内容并生成文字描述**。
          * **JSON 封装与标签：** 将图片描述和本地路径封装成你指定的 JSON 格式 `{"description": "...", "imgpath": "..."}`，并用 `[image_info]` 标签包裹，然后将这个字符串插入到原文档对应的文本位置，以便后续文本分块时能一起处理。
      * **文本提取与清洗：** 从文档中提取纯文本内容，并进行基础清洗（去除多余空格、换行符等）。
3.  **分块与嵌入：**
      * **分块策略：** 使用 LangChain 的 `RecursiveCharacterTextSplitter` 对处理后的文本（包含图片信息标签）进行分块。
      * **高质量嵌入：** 调用 `amazon.titan-embed-image-v1` 模型将每个文本块转换为向量嵌入。
4.  **知识库存储：**
      * 将分块后的文本内容、对应的向量嵌入、原始文件元数据以及任何图片信息JSON（如果作为单独字段存储）存储到 **Milvus Lite** 向量数据库中。

### 1.2 相关文件与职责

  * `src/rag/main.py`: 作为入口点，处理文件上传请求，并调用 `src/rag/utils/document_processor.py`。
  * `src/rag/utils/document_processor.py` (新增文件/模块): 负责文档解析、图片提取、LLM描述图片、文本清洗、分块和调用嵌入模型。
  * `src/rag/utils/milvus_manager.py` (新增文件/模块): 负责 Milvus Lite 的连接、集合创建、数据插入等操作。
  * `rag/knowledge/images/`: 存储提取出的图片。

-----

## 2\. 知识检索与初步整合 (传统编程实现 + LLM 调用)

这个阶段同样主要通过传统编程方式进行检索和初步的数据整合，不涉及 CrewAI Agent。

### 2.1 核心流程

1.  **用户问题接收：** 用户通过前端界面或 API 提交问题。
2.  **问题嵌入：** 将用户问题通过 `amazon.titan-embed-image-v1` 模型转换为向量嵌入。
3.  **混合检索：**
      * 使用用户问题的嵌入在 **Milvus Lite** 中进行**语义搜索**，召回一批相关的文档片段。
      * **（可选）结合关键词搜索/元数据过滤：** 如果有需求，可以在这里加入关键词匹配或基于元数据的过滤，以提高召回率和精确性。
4.  **重排 (Re-ranking)：**
      * 将检索到的文档片段（通常是几十个）与用户原始查询一起发送给 `RERANK_MODEL=cohere.rerank-v3-5:0` 模型进行重排。
      * 根据重排分数，选择 **Top K** 个最相关的文档片段。
5.  **LLM 初步整合：**
      * 将用户问题和重排后的 Top K 文档片段（作为上下文）发送给一个强大的 LLM（例如 `MODEL=bedrock/apac.anthropic.claude-3-haiku-20240307-v1:0`）。
      * **LLM 的任务：** 让 LLM 对这些召回的数据集与原始用户问题进行**初步的理解和整合**。
      * **推理成步骤：** 关键在于，让 LLM 将这些信息**推理成一步一步的指导或解决方案**，直接告诉用户应该怎么做，而不是一个简单的答案。例如，如果用户问“如何报销差旅费”，LLM 不仅要给出政策，还要给出“第一步：准备发票，第二步：填写报销单，第三步：提交给财务部”这样的步骤。
      * **输出格式：** LLM 输出的结果应该是一个结构化的文本，清晰地列出步骤。

### 2.2 相关文件与职责

  * `src/rag/main.py`: 作为入口点，处理用户问题请求，并调用 `src/rag/utils/retriever.py`。
  * `src/rag/utils/retriever.py` (新增文件/模块): 封装了问题嵌入、Milvus 查询、重排逻辑和对 LLM 的初步整合调用。

-----

## 3\. 最终报告生成与展示 (CrewAI Agent 介入)

在这个阶段，CrewAI Agent 将介入，对经过初步整合的步骤进行**进一步的处理、细化和格式化**，生成最终的、用户友好的报告或交互式回复。

### 3.1 核心流程

1.  **Agent 接收初步整合结果：** CrewAI 中的一个或多个 Agent 接收到第二阶段 LLM 生成的“一步一步的指导”文本。
2.  **Agent 的任务与推理：**
      * **细化与补充：** Agent 可以根据其角色和目标，进一步细化这些步骤，例如添加更多细节、注意事项，或者从其内部知识中补充额外的信息。
      * **格式化：** Agent 的一个重要任务是将这些指导性的步骤格式化为用户友好的报告或回复。这可能包括使用 Markdown 格式、列表、加粗等，以便于阅读和理解。
      * **图片信息处理：** 如果 LLM 初步整合的结果中包含 `[image_info]` 标签，Agent 需要理解这些标签，并将其转化为用户界面可以渲染的指令（例如，告知前端“此处应展示图片 `imgpath`，描述为 `description`”）。Agent 本身不渲染图片，只是输出渲染图片所需的元数据。
3.  **最终报告输出：** Agent 生成最终的、可直接呈现给用户的报告文本。

### 3.2 相关文件与职责

  * `src/rag/crew.py`: 定义 Crew、Agent 和 Task。
      * **Agent 角色：** 例如，“报告撰写专家”、“交互指导员”。
      * **Task：** 接收 LLM 初步整合的文本，并将其转换为最终报告。
  * `src/rag/config/agents.yaml`: 定义报告生成 Agent 的角色、目标、背景故事和可能使用的工具（如果需要）。
  * `src/rag/config/tasks.yaml`: 定义报告生成任务。
  * `src/rag/main.py`: 接收 Agent 的最终输出，并将其返回给前端展示。

-----

## 项目结构更新建议

为了更好地体现上述设计，我会建议在 `src/rag` 目录下新增一些工具类或实用程序模块：

```
rag
├── knowledge
│   └── user_preference.txt
│   └── images/ # 新增，用于存储提取的图片
├── pyproject.toml
├── src
│   └── rag
│       ├── __init__.py
│       ├── config
│       │   ├── agents.yaml
│       │   └── tasks.yaml
│       ├── crew.py
│       ├── main.py
│       ├── utils # 新增目录，存放不涉及Agent的通用工具
│       │   ├── __init__.py
│       │   ├── document_processor.py # 处理文档、图片、分块、嵌入
│       │   ├── milvus_manager.py     # Milvus Lite操作
│       │   └── retriever.py          # 检索、重排、LLM初步整合
│       └── tools # 这个目录现在主要存放Agent会直接调用的LangChain Tools，或者可以考虑移除，如果Agent仅使用LLM推理。
│           └── __init__.py
│           └── custom_llm_tool.py # 如果有Agent需要以Tool形式调用特定LLM功能
└── tests
```

-----

这个修订后的设计更清晰地划分了职责：

  * **传统编程：** 负责数据管道（摄取、清洗、嵌入、存储、基础检索、重排），这些是确定性高、逻辑清晰的流程。
  * **LLM 直接调用：** 在检索后进行**初步的数据整合和步骤推理**，发挥 LLM 在理解和生成结构化输出方面的能力。
  * **CrewAI Agent：** 专注于**复杂推理、多步决策、细化输出和生成最终报告**，真正体现 Agent 编排的价值。

这个设计能更好地利用每个组件的优势，并且避免了在不必要的地方引入 Agent 的开销。
